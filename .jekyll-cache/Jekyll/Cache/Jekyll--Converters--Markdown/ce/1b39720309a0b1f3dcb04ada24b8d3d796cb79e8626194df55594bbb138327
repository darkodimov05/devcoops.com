I"V<p>There are a lot of reasons for moving your local files into your AWS S3 bucket. Maybe you want to host your static files with S3 or you want to make a backup of your database, etc… In this tutorial we will show how to do this in a quck and efficient way with AWS CLI, whithout wasting your time by clicking on your AWS Console Management buttons. Using AWS CLI will speed up your uploading process and also you can include a lot of options with only one command.</p>

<h2 id="prerequisites">Prerequisites</h2>
<ul>
  <li>You should already have an existing AWS account</li>
  <li>Make sure that you are logged into your Linux machine as a user with <code class="language-plaintext highlighter-rouge">sudo</code> privileges</li>
  <li>Have installed <a href="https://devcoops.com/install-AWS-CLI-and-create-multiple-named-profiles/">AWS CLI and learned how to switch between multiple named profiles</a></li>
</ul>

<h2 id="examples">Examples</h2>
<p><strong>Step 1</strong>. If you meet all the above requirements, it’s a good practise to list all your available buckets, so you should be able to find your desired S3 bucket.
To do a simple list command run the following:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">ls</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">Output</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2019-10-03 18:58:59 cf-templates-zdqxzzv9nyis-us-east-1
2019-10-08 15:19:05 devcoops-bucket
</code></pre></div></div>
<p>In this tutorial our desired <code class="language-plaintext highlighter-rouge">bucket</code> will be <code class="language-plaintext highlighter-rouge">devcoops-bucket</code>. So, if you want to list all the objects inside your desired bucket run:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">ls </span>s3://devcoops-bucket
</code></pre></div></div>
<p>This will list all the objects in the <code class="language-plaintext highlighter-rouge">devcoops-bucket</code>. If you want to see the files in a previously listed object you should use the same command and put <code class="language-plaintext highlighter-rouge">/name-of-the-object</code>.</p>

<p>You can also use the following command to recursively list objects in a bucket rather than playing with the bucket path:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">ls </span>s3://devcoops-bucket <span class="nt">--recursive</span>
</code></pre></div></div>
<p>If you want to display file size, the total nubmer of objects and calculate the total size run:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">ls </span>s3://devcoops-bucket <span class="nt">--recursive</span> <span class="nt">--human-readable</span> <span class="nt">--summarize</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">Output</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2019-10-03 18:58:59 10 Bytes des.txt
2019-10-08 15:19:05 23 Bytes bes.txt

Total Objects: 2
   Total Size: 33 Bytes
</code></pre></div></div>

<p><strong>Step 2</strong>. The general syntax of copying files goes:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">cp source </span>destination
</code></pre></div></div>
<p>To copy from your local Linux machine to S3:</p>

<p><code class="language-plaintext highlighter-rouge">aws s3 cp [destination-of-the-local-file] S3BuckerURI</code></p>

<p>and the opposite logic:</p>

<p><code class="language-plaintext highlighter-rouge">aws s3 cp S3BuckerURI [destination-of-the-local-file]</code></p>

<p>You can also copy from one S3 bucket to another:</p>

<p><code class="language-plaintext highlighter-rouge">aws s3 cp S3BuckerURI1 S3BuckerURI2</code></p>

<p>To copy a single local file from your machine to S3:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">cp </span>test.txt s3://devcoops-bucket/
</code></pre></div></div>
<p>To copy all your files in a specific folder to S3 into the desired <code class="language-plaintext highlighter-rouge">data</code> directory located in the <code class="language-plaintext highlighter-rouge">devcoops-bucket</code> bucket:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">cp </span>my-data/ s3://devcoops-bucket/data/ <span class="nt">--recursive</span>
</code></pre></div></div>
<p>We can add more complex commands just in case if you want to filter your files:
In this example we will download all the files from an S3 bucket, that are starting with <code class="language-plaintext highlighter-rouge">2019-10-03</code>, but you can edit the filter by your needs:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">cp </span>s3://devcoops-bucket/ my-data/ <span class="nt">--exclude</span> <span class="s2">"*"</span> <span class="nt">--include</span> <span class="s2">"2019-10-03*"</span> <span class="nt">--recursive</span>
</code></pre></div></div>
<p>If your goal is to synchronize a set of files without copying them twice, use the <code class="language-plaintext highlighter-rouge">sync</code> command:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">sync </span>s3://devcoops-bucket/ my-data/
</code></pre></div></div>
<p>The following command is equivalent of the above <code class="language-plaintext highlighter-rouge">cp</code> command:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">sync </span>s3://devcoops-bucket/ my-data/ <span class="nt">--exclude</span> <span class="s2">"*"</span> <span class="nt">--include</span> <span class="s2">"2019-10-03*"</span> <span class="nt">--recursive</span>
</code></pre></div></div>
<p>The difference between <code class="language-plaintext highlighter-rouge">cp</code> and <code class="language-plaintext highlighter-rouge">sync</code> commands is that, if you want to copy multiple files with <code class="language-plaintext highlighter-rouge">cp</code> you must include the <code class="language-plaintext highlighter-rouge">--recursive</code> parameter. The aws s3 <code class="language-plaintext highlighter-rouge">sync</code> command will do this by default, copy a whole directory. It will only copy new/modified files.</p>

<h2 id="conclusion">Conclusion</h2>
<p>In this tutorial we shown you how you can copy your files from and to your AWS S3 bucket. Also we shown you how to add your custom filters to copy some specific files. For more informations you can take a look at the <a href="https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html">AWS CP Documentation</a>.</p>
:ET